[
  {
    "objectID": "label_libraries.html",
    "href": "label_libraries.html",
    "title": "Label Libraries",
    "section": "",
    "text": "We are in the process of developing a set of standardized label libraries to support consistent variable and value labeling across our datasets. These libraries will be available in formats compatible with commonly used statistical software such as R, SPSS, and SAS.\nOur initial focus is on creating a core library covering the standard variables most commonly included in MADC data requests. In the future, we aim to expand this to include form-specific label sets to further streamline data preparation and documentation.\nThis resource is under development, check back soon for updates!\n\n\n\n\n\n\nNote\n\n\n\nComing Soon: The download links below are placeholders. Finalized label libraries will be available here once development is complete.\n\n\n\n\n\nLabel Library\nCSV\nR\nSAS\nSPSS\nStata\n\n\n\n\nStandard Dataset\nDownload\nDownload\nDownload\nDownload\nDownload\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_dictionary.html",
    "href": "data_dictionary.html",
    "title": "Data Dictionary",
    "section": "",
    "text": "This page will provide definitions and documentation for variables used across the Michigan Alzheimer’s Disease Center’s (MADC) research data systems. It will include both standardized fields from the National Alzheimer’s Coordinating Center (NACC) and locally defined variables from MADC-specific protocols.\nWe are currently compiling and validating our data dictionary to ensure accuracy and usability. Once complete, this resource will support consistent data entry, interpretation, and reuse across studies.\n\n\n\n\n\n\nNote\n\n\n\nStay tuned: More to come as we finalize formatting and content.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "request_madrc_data.html",
    "href": "request_madrc_data.html",
    "title": "Request Michigan ADRC Data",
    "section": "",
    "text": "Note\n\n\n\nData Requests Are Open\nWhile we are actively developing a more comprehensive data request system, requestors can use our current Resource Application to submit inquiries. Updated documentation and workflow guidance will be added here as the new system goes live.\n\n\nWe are committed to making data from the Michigan Alzheimer’s Disease Research Center (MADRC) accessible and useful to collaborators, investigators, and the broader scientific community.\nOur team is currently in the process of developing a more robust, transparent workflow for managing both internal and external data requests. This future system will include clearer guidance for requestors, built-in tracking to support timely responses, and improved coordination across our data and research teams.\nIn the meantime, we encourage requestors to use our current Resource Application to initiate new requests. This form helps us gather key information about your study needs, population of interest, and intended data use.\nWe appreciate your patience as we work toward launching a more comprehensive request and review process. Updates to this page, including documentation of the new workflow, will be shared as development progresses.\n\n\n\n Back to top"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "This page showcases scholarly work produced by members of the Data Core in collaboration with investigators at the Michigan Alzheimer’s Disease Research Center (Michigan ADRC). It features peer-reviewed manuscripts, conference posters, and abstracts that reflect our commitment to transparency, collaboration, and advancing Alzheimer’s disease and related dementias (ADRD) research.\nThe publication list is searchable and sortable, and is actively maintained as new work becomes available. Data tools and code-based resources can now be found on the Codebases page.\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Authors\n      \n      \n        Journal/Conference\n      \n      \n        Publication Date - Oldest\n      \n      \n        Publication Date - Newest\n      \n      \n        Categories\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nAuthors\n\n\n\nJournal/Conference\n\n\n\nPublication Date\n\n\n\nCategories\n\n\n\n\n\n\n\n\nMicrostructural integrity of medial temporal lobe in relation to plasma concentration of TDP-43 in older adults with amnestic mild cognitive impairment or dementia\n\n\nDevignes, Q., Pruitt, P.J., Kanaan, N.M., DuBois, K.N., Petscavage, K., Koeppe, R.A., Albin, R.L., Peltier, S., Rahman-Filipiak, A., Giordani, B., Iordan, A.D., Hampstead, B.M.\n\n\nMichigan Alzheimer’s Disease Research Center’s 9th annual Beyond Amyloid Research Symposium\n\n\n5/30/25\n\n\nTDP-43, Medial Temporal Lobe, Mild Cognitive Impairment, Dementia, Plasma Biomarkers, Neuroimaging, Neurodegeneration\n\n\n\n\n\n\nEstablishing the utility of a plasma biomarker panel by comparing to PET gold standards through the STIM study\n\n\nDuBois, K.N., Iordan, A.D., Rahman-Filipiak, A., Albin, R., Koeppe, R., Devignes, Q., Petscavage, K., Perkins, M.D., Khobeir, N., Hampstead, B.M., Kanaan, N.M.\n\n\nMichigan Alzheimer’s Disease Research Center’s 9th annual Beyond Amyloid Research Symposium\n\n\n5/30/25\n\n\nPlasma Biomarkers, PET Imaging, STIM Study, Alzheimer’s Disease, Amyloid, Tau, Clinical Validation\n\n\n\n\n\n\nThe impact of returning individual research results: Program evaluation of the Michigan Alzheimer’s Disease Research Center’s participant feedback program\n\n\nFlores, B., Kohl, H., Maher, A., Posby, B., Gierzynski, T., Whitaker, G., Pleskaczynska, J., Reader, J., Hampstead, B.M., Roberts, S., Rahman-Filipiak, A.\n\n\nMichigan Alzheimer’s Disease Research Center’s 9th annual Beyond Amyloid Research Symposium\n\n\n5/30/25\n\n\nReturn of Results, Participant Engagement, Ethics, Research Communication, Program Evaluation, Alzheimer’s Research, Feedback Mechanisms\n\n\n\n\n\n\nSegregation of attentional networks is associated with visuospatial performance in older adults with cognitive impairment\n\n\nHernandez-Reyes, K., Liu, Y., Petscavage, K.M., Rahman-Filipiak, A., Peltier, S., Giordani, B., Albin, R., Hampstead, B.M., Iordan, A.D.\n\n\nMichigan Alzheimer’s Disease Research Center’s 9th annual Beyond Amyloid Research Symposium\n\n\n5/30/25\n\n\nCognitive Impairment, Attentional Networks, Functional Connectivity, fMRI, Visuospatial Skills, Neurocognition, Network Segregation\n\n\n\n\n\n\nAssociations between visuospatial cognition and amyloid and tau accumulation in amnestic mild cognitive impairment and dementia of Alzheimer’s type\n\n\nKelley, M., Devignes, Q., Harrie, A., Petscavage, K.M., Koeppe, R.A., Albin, R.L., Rahman-Filipiak, A., Iordan, A.D., Giordani, B., Hampstead, B.M., Pruitt, P.J.\n\n\nMichigan Alzheimer’s Disease Research Center’s 9th annual Beyond Amyloid Research Symposium\n\n\n5/30/25\n\n\nAmyloid, Tau, MCI, Dementia, Visuospatial Cognition, PET Imaging, Biomarker Associations\n\n\n\n\n\n\nCharacterizing brain region-specific gene expression changes in the lead exposed mouse brain\n\n\nMatei, E., Morgan, R., Tapaswi, A., Miller, J., Wang, H., Zhou, X., Bakulski, K., Dolinoy, D., Colacino, J.\n\n\nMichigan Alzheimer’s Disease Research Center’s 9th annual Beyond Amyloid Research Symposium\n\n\n5/30/25\n\n\nGene Expression, Lead Exposure, Mouse Models, Environmental Toxicology, Brain Regions, Transcriptomics, Neurotoxicity\n\n\n\n\n\n\nRethinking the obesity paradox: BMI and longitudinal cognitive decline in older adults\n\n\nPal, S., Irfan, B., Reader, J., Bakulski, K., Kavcic, V., Giordani, B.\n\n\nMichigan Alzheimer’s Disease Research Center’s 9th annual Beyond Amyloid Research Symposium\n\n\n5/30/25\n\n\nObesity Paradox, BMI, Cognitive Decline, Aging, Longitudinal Studies, Older Adults, Public Health\n\n\n\n\n\n\nAssessing the role of Aβ and tau in modulating HD-tDCS electric fields in cognitive impairment\n\n\nPardo, C., Devignes, Q., Liu, Y., Petscavage, K., Koeppe, R.A., Peltier, S.J., Albin, R.L., Rahman-Filipiak, A., Iordan, A.D., Hampstead, B.M., Pruitt, P.J.\n\n\nMichigan Alzheimer’s Disease Research Center’s 9th annual Beyond Amyloid Research Symposium\n\n\n5/30/25\n\n\nHD-tDCS, Amyloid, Tau, Neurostimulation, Cognitive Impairment, Electric Field Modeling, Neuromodulation\n\n\n\n\n\n\nSubjective cognitive decline is associated with weaker long-term potentiation-like cortical neuroplasticity in older adults\n\n\nRisto, C., Devignes, Q., Garcia, C., Petscavage, K., Vesia, M., Iordan, A.D., Hampstead, B.M.\n\n\nMichigan Alzheimer’s Disease Research Center’s 9th annual Beyond Amyloid Research Symposium\n\n\n5/30/25\n\n\nSubjective Cognitive Decline, Neuroplasticity, LTP-like Mechanisms, TMS, Older Adults, Cortical Excitability, Cognition\n\n\n\n\n\n\nToward a person-centered return of research results of dementia risk: A pluralistic, constructive expansion\n\n\nBilal Irfan, Emily Wiseman, Jason W Boyd, Jonathan Reader and Annalise Rahman-Filipiak\n\n\nJournal of Alzheimer’s Disease\n\n\n5/1/25\n\n\nDementia Risk, Return of Results, Ethics, Person-Centered Care, Neuroethics, Alzheimer’s Research\n\n\n\n\n\n\nMultidisciplinary stakeholder-informed identification of key characteristics for implementation of workplace genetic testing\n\n\nElizabeth Charnysh, Khyati Sanghavi, Kelly A Ryan, Allison Vogle, Amanda Truhlar, Subhamoy Pal, Jonathan M Reader, J Scott Roberts, Chanita Lee, Alexandra E R Prince and William G Feero\n\n\nHuman Genetics and Genomic Advances\n\n\n1/1/25\n\n\nWorkplace Genetic Testing, Stakeholder Engagement, Implementation Science, Ethics, Precision Medicine\n\n\n\n\n\n\nRetest reliability and reliable change of community-dwelling Black/African American older adults with and without mild cognitive impairment using NIH Toolbox-Cognition Battery and Cogstate Brief Battery for laptop\n\n\nTaylor Rigby, Voyko Kavcic, Sarah R Shair, Tanisha G Hill-Jarrett, Sarah Garcia, Jonathan Reader, Carol Persad, Arijit K Bhaumik, Subhamoy Pal, Benjamin M Hampstead and Bruno Giordani\n\n\nJournal of the International Neuropsychological Society\n\n\n12/20/24\n\n\nComputerized Neuropsychological Assessment, Computerized Cognitive Assessment, Practice Effects, Psychometrics, Reproducibility of Results, Reliability of Tests\n\n\n\n\n\n\nIdentification of amnestic mild cognitive impairment among Black and White community-dwelling older adults using NIH Toolbox Cognition tablet battery\n\n\nTaylor Rigby, Allyson M Gregoire, Jonathan Reader, Yonatan Kahsay, Jordan Fisher, Anson Kairys, Arijit K Bhaumik, Annalise Rahman-Filipiak, Amanda Cook Maher, Benjamin M Hampstead, Judith L Heidebrink, Voyko Kavcic and Bruno Giordani\n\n\nJournal of the International Neuropsychological Society\n\n\n8/18/24\n\n\nComputerized Neuropsychological Assessment, Computerized Cognitive Assessment, Cognition, Psychometrics, Norms, Cross-Cultural, Discriminant Function Analysis\n\n\n\n\n\n\nAlzheimer’s Disease and Related Dementias in Muslim Women: Recommendations for Culturally Sensitive Care\n\n\nBilal Irfan, Ghadeer Ankouni, Jonathan Reader, Navid Seraji-Bozorgzad, Bruno Giordani, Kelly Bakulski, Arijit Bhaumik, Benjamin M Hampstead and Annalise Rahman-Filipiak\n\n\nJournal of Alzheimer’s Disease\n\n\n5/13/24\n\n\nADRD, Muslim Patients, Cultural Care, Religious Beliefs, Gender Sensitivity, Health Equity, Caregiver Roles\n\n\n\n\n\n\nEvaluation of the Uniform Data Set version 3 teleneuropsychological measures\n\n\nTheresa F Gierzynski, Allyson M Gregoire, Jonathan M Reader, Rebecca Pantis, Stephen Campbell, Arijit K Bhaumik, Annalise Rahman-Filipiak, Judith L Heidebrink, Bruno Giordani, Henry Paulson and Benjamin M Hampstead\n\n\nJournal of the International Neuropsychological Society\n\n\n6/27/23\n\n\nTeleneuropsychology, Older Adults, Memory, Cognition, Aging, Mild Cognitive Impairment, Dementia, In-Home Cognitive Assessment\n\n\n\n\n\n\nMendelian Randomization of Dyslipidemia on Cognitive Impairment Among Older Americans\n\n\nMingzhou Fu, Kelly M Bakulski, Cesar Higgins and Erin B Ware\n\n\nFrontiers in Neurology\n\n\n6/23/21\n\n\nBlood Cholesterol, Polygenic Score, Dementia, Mendelian Randomization, Cognitive Domain\n\n\n\n\n\n\nExposure to heavy metals and dementia: Evidence from human and molecular studies\n\n\nKelly M Bakulski\n\n\nNIH Alzheimer’s Disease Research Summit: Path to Precision Medicine for Treatment and Prevention\n\n\n4/22/21\n\n\nNIH Summit, Alzheimer’s Research, Translational Research, Therapy Development, Multi-Stakeholder, Neuropsychiatric Symptoms, Strategic Planning\n\n\n\n\n\n\nType 2 Diabetes and Cognitive Status in the Health and Retirement Study: A Mendelian Randomization Approach\n\n\nErin B Ware, Cristina Morataya, Mingzhou Fu and Kelly M Bakulski\n\n\nFrontiers in Genetics\n\n\n3/25/21\n\n\nMendelian Randomization, Dementia, Health and Retirement Study (HRS), Polygenic Score, Type 2 Diabetes Mellitus\n\n\n\n\n\n\nLaptop-Administered NIH Toolbox and Cogstate Brief Battery in Community-Dwelling Black Adults: Unexpected Pattern of Cognitive Performance between MCI and Healthy Controls\n\n\nAnson Kairys, Ana Daugherty, Voyko Kavcic, Sarah Shair, Carol Persad, Judith Heidebrink, Arijit Bhaumik and Bruno Giordani\n\n\nJournal of the International Neuropsychological Society\n\n\n3/23/21\n\n\nMemory, Computers, Cognition, Dementia, Ethnic Groups, Diagnosis\n\n\n\n\n\n\nTranscriptional profiling of the response to the trichloroethylene metabolite S-(1,2-dichlorovinyl)-L-cysteine revealed activation of the eIF2α/ATF4 integrated stress response in two in vitro placental models\n\n\nElana R Elkin, Kelly M Bakulski, Justin A Colacino, Dave Bridges, Brian A Kilburn, D Randall Armant and Rita Loch-Caruso\n\n\nArchives of Toxicology\n\n\n3/16/21\n\n\nATF4, Integrated Stress Response, Placenta, S-(1,2-dichlorovinyl)-L-cysteine (DCVC), Trichloroethylene\n\n\n\n\n\n\nCumulative Genetic Risk and APOE ε4 Are Independently Associated With Dementia Status in a Multiethnic, Population-Based Cohort\n\n\nKelly M Bakulski, Harita S Vadari, Jessica D Faul, Steven G Heeringa, Sharon L R Kardia, Kenneth M Langa, Jennifer A Smith, Jennifer J Manly, Colter M Mitchell, Kelly S Benke and Erin B Ware\n\n\nNeurology Genetics\n\n\n3/5/21\n\n\nAlzheimer Disease, Association Studies in Genetics, Cognitive Aging, Cognitive Disorders/Dementia, Cohort Studies, Epidemiology, Genetics, Mild Cognitive Impairment (MCI)\n\n\n\n\n\n\nPost-task modulation of resting state EEG differentiates MCI patients from controls\n\n\nVoyko Kavcic, Ana M Daugherty and Bruno Giordani\n\n\nAlzheimer’s & Dementia (Amsterdam, Netherlands)\n\n\n2/20/21\n\n\nEEG Markers, Mild Cognitive Impairment, Neuropsychology, Resting‐State Electroencephalography (rsEEG)\n\n\n\n\n\n\nNo matching items\n Back to top"
  },
  {
    "objectID": "assets/team_bios/jian_kang.html",
    "href": "assets/team_bios/jian_kang.html",
    "title": "Jian Kang, PhD, MS",
    "section": "",
    "text": "Jian Kang, PhD, MS; Data Management and Statistical Core Affiliated Faculty, Associate Chair for Research, and Professor of Biostatistics\n\n\n\n\nDr. Kang’s primary research interests are in developing statistical methods for large-scale complex biomedical data with application in precision medicine, imaging, epidemiology and genetics.\nFaculty Profile\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "assets/team_bios/haley_payne.html",
    "href": "assets/team_bios/haley_payne.html",
    "title": "Haley Payne",
    "section": "",
    "text": "Haley Payne, Research Assistant\n\n\n\n\nHaley joined the Michigan Alzheimer’s Disease Center in February of 2024 as a member of the Data Core Team as a Research Assistant (Temp). She earned her B.S. in Neuroscience and Psychology from Michigan State University in 2023. Haley’s role in data core includes prepping and handling visit packets for various studies, entering data into REDCap, and assisting with the NACC verification process. Haley also provides support for other cores across the center when needed. Currently, Haley is expanding her skills by assisting the computational team of our Neuroimaging Core. In her free time, Haley loves going to the gym and traveling the world!\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "assets/team_bios/miranda_cooper.html",
    "href": "assets/team_bios/miranda_cooper.html",
    "title": "Miranda Cooper",
    "section": "",
    "text": "Miranda Cooper, Data Analyst / Programmer\n\n\n\n\nMiranda is a Data Analyst / Programmer with a Master of Science in Information and over nine years of experience in workflow automation, data management, and analytics. She specializes in building scalable automation systems and applications to streamline operations and is currently expanding her expertise in cloud data infrastructure by learning dbt. Passionate about R, Python, Power Automate, and data pipeline automation, she enjoys discussing innovative ways to optimize processes and improve efficiency through automation. Outside of work, Miranda once walked 50,000 steps in a single day - from Troy, MI, to the Detroit Zoo and back - and loves treasure hunting at garage sales and reselling unique finds on eBay.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "assets/team_bios/ana_daugherty.html",
    "href": "assets/team_bios/ana_daugherty.html",
    "title": "Ana Daugherty",
    "section": "",
    "text": "Ana Daugherty, PhD; Data Management and Statistical Core Affiliated Faculty; Associate Professor, Institute of Gerontology, Wayne State University\n\n\n\n\nDr. Daugherty is a cognitive neuroscientist with a specialty in aging, Alzheimer’s disease and related dementia. Her research characterizes individual differences in aging across the adult lifespan to identify both risk and protective factors that modify changes in the brain, and related changes in thinking and memory functions. The long-term goal of her work is to reduce disparities in late-life cognitive health.\nShe directs the Detroit Aging Brain Study: a community-partnered longitudinal study going on over 22 years in the Metro Detroit area to study changes in brain structure and function across the healthy, adult lifespan.\nShe is affiliated faculty in the Michigan Alzheimer’s Disease Research Center, lead of its Research Education Component, and co-investigator of the cener’s Data Management and Statistical Analysis Core and NeuroImaging Core.\nShe is also affiliated faculty and serves on the steering committee of the Translational Neuroscience Program (Wayne State University School of Medicine).\nFaculty Profile\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "assets/team_bios/kelly_bakulski.html",
    "href": "assets/team_bios/kelly_bakulski.html",
    "title": "Kelly M. Bakulski, PhD",
    "section": "",
    "text": "Kelly Bakulski, PhD; Data Management and Statistical Core Leader; Associate Professor, Epidemiology, University of Michigan School of Public Health\n\n\n\n\nDr. Kelly Bakulski is an Associate Professor with tenure in the Department of Epidemiology at the University of Michigan School of Public Health. She is a molecular epidemiologist and environmental health scientist who investigates the roles of environmental chemicals, epigenetics, and genetics in the etiology of neurological diseases. Her team develops biomarker and cell type specific tools to inform population-based approaches. She has published over 110 peer-reviewed articles and has had continuous funding support from the National Institutes of Health. Dr. Bakulski was granted the 2024 Mid-career Biosciences Faculty Achievement Recognition Award for outstanding research performance at the University of Michigan. She is passionate about mentoring and is a recipient of the School of Public Health Excellence in Teaching Award.\nFaculty Profile\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "assets/team_bios/kenneth_petscavage.html",
    "href": "assets/team_bios/kenneth_petscavage.html",
    "title": "Kenneth Petscavage",
    "section": "",
    "text": "Kenneth Petscavage, Data Analyst / Programmer\n\n\n\n\nKenny joined the Michigan Alzheimer’s Disease Center in the summer of 2023 as a member of the data core team as a Data Analyst/Programmer. He earned his B.S. in Statistics from Virginia Tech in 2021 and an MPH in Global Health Epidemiology from the University of Michigan in 2023. Kenny’s role includes working with researchers and staff to improve data management processes and support data analysis, primarily working in R, REDCap, and Power Automate. He also helps support collaborative projects between the MADC and another research program at U-M, the RP-CNBI. Kenny is currently working on learning SQL and enjoys running in his free time.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "assets/codebases/upload_bal_data_to_redcap.html",
    "href": "assets/codebases/upload_bal_data_to_redcap.html",
    "title": "Upload Biomarker and Longitudinal (BAL) data to REDCap system",
    "section": "",
    "text": "Play with Markdown settings\nCreate script to be a set of functions in the madRc package/executablev\nCreate Example\nUpload REDCap fields/Zip to project"
  },
  {
    "objectID": "assets/codebases/upload_bal_data_to_redcap.html#to-do",
    "href": "assets/codebases/upload_bal_data_to_redcap.html#to-do",
    "title": "Upload Biomarker and Longitudinal (BAL) data to REDCap system",
    "section": "",
    "text": "Play with Markdown settings\nCreate script to be a set of functions in the madRc package/executablev\nCreate Example\nUpload REDCap fields/Zip to project"
  },
  {
    "objectID": "assets/codebases/upload_bal_data_to_redcap.html#pre-work-potentially-required",
    "href": "assets/codebases/upload_bal_data_to_redcap.html#pre-work-potentially-required",
    "title": "Upload Biomarker and Longitudinal (BAL) data to REDCap system",
    "section": "Pre-work potentially required",
    "text": "Pre-work potentially required\nThe variable names provided by the National Alzheimer’s Coordinating Center (NACC) may not match the existing fields in your REDCap project when uploading the data for the first time. As a result, corresponding variables must be created in REDCap before the upload can proceed. Keep in mind that not all NACC variables are needed locally, and any unneeded fields are excluded in the upload script by commenting them out.\nThe REDCap form is set up as a repeating instrument, using the variable Sample to indicate the type of biomarker: ABeta40, ABeta42, or pTau217. To support this structure, we enabled both repeating instruments and repeating events in the REDCap project. Each event (e.g., visit) includes the BAL Data Returned by NACC as a separate repeating form, independent of other forms within that event. Additionally, we added a custom label, [bal_sample], to each repeating instance to clearly display which sample the form represents.\nThe included ZIP file (BALDataReturnedByNAC_2025-01-03_0854.zip) contains the REDCap form used by the Michigan Alzheimer’s Disease Center (MADC).\nPlease note: You will need to update the variable names in this form to match those used in your local REDCap project in order for the associated script to function correctly."
  },
  {
    "objectID": "assets/codebases/upload_bal_data_to_redcap.html#extract",
    "href": "assets/codebases/upload_bal_data_to_redcap.html#extract",
    "title": "Upload Biomarker and Longitudinal (BAL) data to REDCap system",
    "section": "Extract",
    "text": "Extract\nAccess to BAL data will be granted by NACC to individuals on an approved distribution list. The BAL data can be downloaded using the password provided in a separate email from NACC. Files should be saved to the designated folder; all .xlsx files are excluded from version control via the .gitignore file.\n#| label: Setup\n#| eval: false\n#| echo: true\n#| message: false\n#| warning: false\n\n# install.packages(\"tidyverse\")  #TODO: If not installed, install tidyverse for data munging\n# install.packages(\"readxl\")  #TODO: If not installed, install readxl to get BAL data\n# install.packages(\"RCurl\")  #TODO: If not installed, install RCurl for API to REDCap\n# install.packages(\"tidylog\")  #TODO: If not installed, install tidylog for support\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(RCurl)\nlibrary(tidylog)\n#| label: Extract\n#| eval: false\n#| echo: true\n#| message: false\n#| warning: false\n\ndf_ab40 &lt;- read_xlsx(\"Site 43 AB40 BAL0008 Return 11.xlsx\")\ndf_ab42 &lt;- read_xlsx(\"Site 43 AB42 BAL0008 Return 11.xlsx\")\ndf_ptau217 &lt;- read_xlsx(\"Site 43 pTau217 BAL0008 Return 11.xlsx\")\ndf_nfl_gfap &lt;- read_xlsx(\"Site 43 N2PB BAL0008 Return 11.xlsx\")\n\n# The below function downloads data from the MADC's UMMAP General REDCap project which contains the forms and fields needed for matching and uploading into the correct project. Your group will have a different project where this information is stored.\n\n# If obtaining the fields is of interest, please see XXXXXX\n\ndownload_ummap_general_data &lt;- function(config = \"~/Dropbox (University of Michigan)/config copy.R\"){ #TODO: update to where your configuration file is located\n  # The config file needs to contain the REDCAP_API_URI and REDCAP_API_TOKEN_UMMAPGENERAL variables as strings where the URI is the URI and the TOKEN is your API TOKEN, respectively\n  source(config)\n  ummapgen &lt;- postForm(\n    uri=REDCAP_API_URI,\n    token=REDCAP_API_TOKEN_UMMAPGENERAL,\n    content='record',\n    format='csv',\n    type='flat',\n    rawOrLabel='raw',\n    rawOrLabelHeaders='raw',\n    exportCheckboxLabel='false',\n    exportSurveyFields='false',\n    exportDataAccessGroups='false',\n    returnFormat='csv'\n  )\n  df_ummapgen &lt;&lt;- read_csv(ummapgen, col_types = cols(.default = col_character()))\n}\n\ndownload_ummap_general_data()"
  },
  {
    "objectID": "assets/codebases/upload_bal_data_to_redcap.html#transform",
    "href": "assets/codebases/upload_bal_data_to_redcap.html#transform",
    "title": "Upload Biomarker and Longitudinal (BAL) data to REDCap system",
    "section": "Transform",
    "text": "Transform\nSome variables will need to be modified or reformatted to match the structure of the REDCap form created during the Pre-work step.\n#| label: Transform\n#| eval: false\n#| echo: true\n#| message: false\n#| warning: false\n\ndf_ummapgen_t &lt;- df_ummapgen %&gt;%\n  select(\n    subject_id,\n    redcap_event_name, # Need this for matching correct event for upload\n    date_of_draw\n  ) %&gt;%\n  mutate(date_of_draw = as.Date(date_of_draw)) # For merging with data from NACC\n\ndf_ab40_t &lt;- df_ab40 %&gt;%\n  mutate(bal_sample = \"ABeta40\", # Needed for repeating form identification upload to REDCap\n         redcap_event_name = NA_character_, # Needed for upload to longitudinal REDCap project\n         redcap_repeat_instrument = \"bal_data_returned_by_nacc\", # Needed for upload to repeating form project\n         redcap_repeat_instance = 1, # Needed for repeating form identification upload to REDCap\n         bal_data_returned_by_nacc_complete = 2, # Needed to mark form complete\n         `Collection Date` = as.Date(`Collection Date`, format = \"%m/%d/%Y\")) %&gt;% # Needed for date format upload to REDCap \n  left_join(df_ummapgen_t, by = c(\"PT ID\" = \"subject_id\", \"Collection Date\" = \"date_of_draw\")) %&gt;% \n  select( # Select and rename in the same step\n    # `ADRC Site`\n    subject_id = `PT ID`,\n    redcap_event_name = redcap_event_name.y, # .y to get from df_ummapgen_t\n    redcap_repeat_instrument,\n    redcap_repeat_instance,\n    bal_sample,\n    bal_barcode = `Barcode`,\n    bal_kit_number = `Kit Number`,\n    bal_collection_date = `Collection Date`,\n    bal_specimen_quantity = `Specimen Quantity`,\n    # `Unit of Measure`\n    # `LAB_ID`\n    # `Lab_Study_ID`,\n    bal_analysis_date = `Analysis Date`,\n    # `INST_ID`\n    # `Assay_Platform`\n    # `Assay_Name`\n    bal_assay_lot_no = `Assay_Lot_No.`,\n    bal_data_pg_ml = `ABeta40 Data (pg/mL)`,\n    bal_lab_freeze_thaw = `Lab Freeze Thaw`,\n    bal_flagged_biomarkers = `Flagged Biomarkers`,\n    bal_additional_information = `Additional Information`,\n    bal_data_returned_by_nacc_complete\n  )\n\ndf_ab42_t &lt;- df_ab42 %&gt;% \n  mutate(bal_sample = \"ABeta42\", # Needed for repeating form identification upload to REDCap\n         redcap_event_name = NA_character_, # Needed for upload to longitudinal REDCap project\n         redcap_repeat_instrument = \"bal_data_returned_by_nacc\", # Needed for upload to repeating form project\n         redcap_repeat_instance = 2, # Needed for repeating form identification upload to REDCap\n         bal_data_returned_by_nacc_complete = 2, # Needed to mark form complete\n         `Collection Date` = as.Date(`Collection Date`, format = \"%m/%d/%Y\")) %&gt;% # Needed for date format upload to REDCap \n  left_join(df_ummapgen_t, by = c(\"PT ID\" = \"subject_id\", \"Collection Date\" = \"date_of_draw\")) %&gt;%\n  select( # Select and rename in the same step\n    # `ADRC Site`\n    subject_id = `PT ID`,\n    redcap_event_name = redcap_event_name.y, # .y to get from df_ummapgen_t\n    redcap_repeat_instrument,\n    redcap_repeat_instance,\n    bal_sample,\n    bal_barcode = `Barcode`,\n    bal_kit_number = `Kit Number`,\n    bal_collection_date = `Collection Date`,\n    bal_specimen_quantity = `Specimen Quantity`,\n    # `Unit of Measure`\n    # `LAB_ID`\n    # `Lab_Study_ID`,\n    bal_analysis_date = `Analysis Date`,\n    # `INST_ID`\n    # `Assay_Platform`\n    # `Assay_Name`\n    bal_assay_lot_no = `Assay_Lot_No.`,\n    bal_data_pg_ml = `ABeta42 Data (pg/mL)`,\n    bal_lab_freeze_thaw = `Lab Freeze Thaw`,\n    bal_flagged_biomarkers = `Flagged Biomarkers`,\n    bal_additional_information = `Additional Information`,\n    bal_data_returned_by_nacc_complete\n  )\n\ndf_ptau217_t &lt;- df_ptau217 %&gt;% \n  mutate(bal_sample = \"pTau217\", # Needed for repeating form identification upload to REDCap\n         redcap_event_name = NA_character_, # Needed for upload to longitudinal REDCap project\n         redcap_repeat_instrument = \"bal_data_returned_by_nacc\", # Needed for upload to repeating form project\n         redcap_repeat_instance = 3, # Needed for repeating form identification upload to REDCap\n         bal_data_returned_by_nacc_complete = 2, # Needed to mark form complete\n         `Collection Date` = as.Date(`Collection Date`, format = \"%m/%d/%Y\")) %&gt;% # Needed for date format upload to REDCap \n  left_join(df_ummapgen_t, by = c(\"PT ID\" = \"subject_id\", \"Collection Date\" = \"date_of_draw\")) %&gt;%\n  select( # Select and rename in the same step\n    # `ADRC Site`\n    subject_id = `PT ID`,\n    redcap_event_name = redcap_event_name.y, # .y to get from df_ummapgen_t\n    redcap_repeat_instrument,\n    redcap_repeat_instance,\n    bal_sample,\n    bal_barcode = `Barcode`,\n    bal_kit_number = `Kit Number`,\n    bal_collection_date = `Collection Date`,\n    bal_specimen_quantity = `Specimen Quantity`,\n    # `Unit of Measure`\n    # `LAB_ID`\n    # `Lab_Study_ID`,\n    bal_analysis_date = `Analysis Date`,\n    # `INST_ID`\n    # `Assay_Platform`\n    # `Assay_Name`\n    bal_assay_lot_no = `Assay_Lot_No.`,\n    bal_data_pg_ml = `pTau217 Conc (pg/mL)`,\n    bal_lab_freeze_thaw = `Lab Freeze Thaw`,\n    bal_flagged_biomarkers = `Flagged Biomarkers`,\n    bal_additional_information = `Additional Information`,\n    bal_data_returned_by_nacc_complete\n  )\n\ndf_nfl_t &lt;- df_nfl_gfap %&gt;% \n  mutate(bal_sample = \"NfL\", # Needed for repeating form identification upload to REDCap\n         redcap_event_name = NA_character_, # Needed for upload to longitudinal REDCap project\n         redcap_repeat_instrument = \"bal_data_returned_by_nacc\", # Needed for upload to repeating form project\n         redcap_repeat_instance = 4, # Needed for repeating form identification upload to REDCap\n         bal_data_returned_by_nacc_complete = 2, # Needed to mark form complete\n         `Collection Date` = as.Date(`Collection Date`, format = \"%m/%d/%Y\")) %&gt;% # Needed for date format upload to REDCap \n  left_join(df_ummapgen_t, by = c(\"PT ID\" = \"subject_id\", \"Collection Date\" = \"date_of_draw\")) %&gt;%\n  select( # Select and rename in the same step\n    # `ADRC Site`\n    subject_id = `PT ID`,\n    redcap_event_name = redcap_event_name.y, # .y to get from df_ummapgen_t\n    redcap_repeat_instrument,\n    redcap_repeat_instance,\n    bal_sample,\n    bal_barcode = `Barcode`,\n    bal_kit_number = `Kit Number`,\n    bal_collection_date = `Collection Date`,\n    bal_specimen_quantity = `Specimen Quantity`,\n    # `Unit of Measure`\n    # `LAB_ID`\n    # `Lab_Study_ID`,\n    bal_analysis_date = `Analysis Date`,\n    # `INST_ID`\n    # `Assay_Platform`\n    # `Assay_Name`\n    bal_assay_lot_no = `Assay_Lot_No.`,\n    bal_data_pg_ml = `NFL Conc (pg/mL)`,\n    bal_lab_freeze_thaw = `Lab Freeze Thaw`,\n    bal_flagged_biomarkers = `Flagged Biomarkers`,\n    bal_additional_information = `Additional Information`,\n    bal_data_returned_by_nacc_complete\n  )\n\ndf_gfap_t &lt;- df_nfl_gfap %&gt;% \n  mutate(bal_sample = \"GFAP\", # Needed for repeating form identification upload to REDCap\n         redcap_event_name = NA_character_, # Needed for upload to longitudinal REDCap project\n         redcap_repeat_instrument = \"bal_data_returned_by_nacc\", # Needed for upload to repeating form project\n         redcap_repeat_instance = 5, # Needed for repeating form identification upload to REDCap\n         bal_data_returned_by_nacc_complete = 2, # Needed to mark form complete\n         `Collection Date` = as.Date(`Collection Date`, format = \"%m/%d/%Y\")) %&gt;% # Needed for date format upload to REDCap \n  left_join(df_ummapgen_t, by = c(\"PT ID\" = \"subject_id\", \"Collection Date\" = \"date_of_draw\")) %&gt;%\n  select( # Select and rename in the same step\n    # `ADRC Site`\n    subject_id = `PT ID`,\n    redcap_event_name = redcap_event_name.y, # .y to get from df_ummapgen_t\n    redcap_repeat_instrument,\n    redcap_repeat_instance,\n    bal_sample,\n    bal_barcode = `Barcode`,\n    bal_kit_number = `Kit Number`,\n    bal_collection_date = `Collection Date`,\n    bal_specimen_quantity = `Specimen Quantity`,\n    # `Unit of Measure`\n    # `LAB_ID`\n    # `Lab_Study_ID`,\n    bal_analysis_date = `Analysis Date`,\n    # `INST_ID`\n    # `Assay_Platform`\n    # `Assay_Name`\n    bal_assay_lot_no = `Assay_Lot_No.`,\n    bal_data_pg_ml = `GFAP Conc (pg/mL)`,\n    bal_lab_freeze_thaw = `Lab Freeze Thaw`,\n    bal_flagged_biomarkers = `Flagged Biomarkers`,\n    bal_additional_information = `Additional Information`,\n    bal_data_returned_by_nacc_complete\n  )"
  },
  {
    "objectID": "assets/codebases/upload_bal_data_to_redcap.html#audit-collection-date-from-nacc-versus-redcap",
    "href": "assets/codebases/upload_bal_data_to_redcap.html#audit-collection-date-from-nacc-versus-redcap",
    "title": "Upload Biomarker and Longitudinal (BAL) data to REDCap system",
    "section": "Audit Collection Date from NACC versus REDCap",
    "text": "Audit Collection Date from NACC versus REDCap\nAny records missing a redcap_event_name indicate a mismatch between the sample’s Collection Date and the corresponding REDCap event. These discrepancies must be reconciled before proceeding. Once all IDs have been matched to the appropriate events, this step can be skipped in future uploads.\n#| label: Audit\n#| eval: false\n#| echo: true\n#| message: false\n#| warning: false\n\ndf_ab40_a &lt;- df_ab40_t %&gt;% \n  filter(is.na(redcap_event_name))\n\ndf_ab42_a &lt;- df_ab42_t %&gt;% \n  filter(is.na(redcap_event_name))\n\ndf_ptau217_a &lt;- df_ptau217_t %&gt;% \n  filter(is.na(redcap_event_name))\n\ndf_nfl_a &lt;- df_nfl_t %&gt;% \n  filter(is.na(redcap_event_name))\n\ndf_gfap_a &lt;- df_gfap_t %&gt;% \n  filter(is.na(redcap_event_name))"
  },
  {
    "objectID": "assets/codebases/upload_bal_data_to_redcap.html#quick-fix",
    "href": "assets/codebases/upload_bal_data_to_redcap.html#quick-fix",
    "title": "Upload Biomarker and Longitudinal (BAL) data to REDCap system",
    "section": "Quick Fix",
    "text": "Quick Fix\nSome records may require manual correction if there is a discrepancy between the blood draw date recorded in the UMMAP General form and the blood draw date in the BAL data. These conflicts should be reviewed with each upload (e.g. visit_04_arm_1 and baseline_arm_1).\n#| label: Quick Fix\n#| eval: false\n#| echo: true\n#| message: false\n#| warning: false\n\ndf_ab40_t2 &lt;- df_ab40_t %&gt;% \n  mutate(redcap_event_name = case_when(\n    subject_id == \"UM00001731\" ~ \"visit_03_arm_1\",\n    subject_id == \"UM00003215\" ~ \"visit_01_arm_1\",\n    subject_id == \"UM00001529\" ~ \"visit_05_arm_1\",\n    subject_id == \"UM00001869\" ~ \"visit_02_arm_1\",\n    subject_id == \"UM00001640\" ~ \"visit_05_arm_1\",\n    subject_id == \"UM00002188\" ~ \"visit_01_arm_1\",\n    subject_id == \"UM00003414\" ~ \"baseline_arm_1\",\n    TRUE ~ redcap_event_name\n  ))\n\ndf_ab42_t2 &lt;- df_ab42_t %&gt;% \n  mutate(redcap_event_name = case_when(\n    subject_id == \"UM00001731\" ~ \"visit_03_arm_1\",\n    subject_id == \"UM00003215\" ~ \"visit_01_arm_1\",\n    subject_id == \"UM00001529\" ~ \"visit_05_arm_1\",\n    subject_id == \"UM00001869\" ~ \"visit_02_arm_1\",\n    subject_id == \"UM00001640\" ~ \"visit_05_arm_1\",\n    subject_id == \"UM00002188\" ~ \"visit_01_arm_1\",\n    subject_id == \"UM00003414\" ~ \"baseline_arm_1\",\n    TRUE ~ redcap_event_name\n  ))\n\ndf_ptau217_t2 &lt;- df_ptau217_t %&gt;% \n  mutate(redcap_event_name = case_when(\n    subject_id == \"UM00001731\" ~ \"visit_03_arm_1\",\n    subject_id == \"UM00003215\" ~ \"visit_01_arm_1\",\n    subject_id == \"UM00001529\" ~ \"visit_05_arm_1\",\n    subject_id == \"UM00001869\" ~ \"visit_02_arm_1\",\n    subject_id == \"UM00001640\" ~ \"visit_05_arm_1\",\n    subject_id == \"UM00002188\" ~ \"visit_01_arm_1\",\n    subject_id == \"UM00003414\" ~ \"baseline_arm_1\",\n    TRUE ~ redcap_event_name\n  ))\n\ndf_nfl_t2 &lt;- df_nfl_t %&gt;% \n  mutate(redcap_event_name = case_when(\n    subject_id == \"UM00001731\" ~ \"visit_03_arm_1\",\n    subject_id == \"UM00003215\" ~ \"visit_01_arm_1\",\n    subject_id == \"UM00001529\" ~ \"visit_05_arm_1\",\n    subject_id == \"UM00001869\" ~ \"visit_02_arm_1\",\n    subject_id == \"UM00001640\" ~ \"visit_05_arm_1\",\n    subject_id == \"UM00002188\" ~ \"visit_01_arm_1\",\n    subject_id == \"UM00003414\" ~ \"baseline_arm_1\",\n    TRUE ~ redcap_event_name\n  ))\n\ndf_gfap_t2 &lt;- df_gfap_t %&gt;% \n  mutate(redcap_event_name = case_when(\n    subject_id == \"UM00001731\" ~ \"visit_03_arm_1\",\n    subject_id == \"UM00003215\" ~ \"visit_01_arm_1\",\n    subject_id == \"UM00001529\" ~ \"visit_05_arm_1\",\n    subject_id == \"UM00001869\" ~ \"visit_02_arm_1\",\n    subject_id == \"UM00001640\" ~ \"visit_05_arm_1\",\n    subject_id == \"UM00002188\" ~ \"visit_01_arm_1\",\n    subject_id == \"UM00003414\" ~ \"baseline_arm_1\",\n    TRUE ~ redcap_event_name\n  ))"
  },
  {
    "objectID": "assets/codebases/upload_bal_data_to_redcap.html#load",
    "href": "assets/codebases/upload_bal_data_to_redcap.html#load",
    "title": "Upload Biomarker and Longitudinal (BAL) data to REDCap system",
    "section": "Load",
    "text": "Load\nOnce the data have been transformed to match the REDCap format, they can be uploaded either via the REDCap API or through manual import using the web interface.\nEnsure all csv files are included in the .gitignore file (i.e., *.csv).\n#| label: Load\n#| eval: false\n#| echo: true\n#| message: false\n#| warning: false\n\nwrite_csv(df_ab40_t2, str_c(today(), \" BAL ABeta40 from NACC Upload.csv\")) # Attach date of upload to transformed file\nwrite_csv(df_ab42_t2, str_c(today(), \" BAL ABeta42 from NACC Upload.csv\")) # Attach date of upload to transformed file\nwrite_csv(df_ptau217_t2, str_c(today(), \" BAL pTau217 from NACC Upload.csv\")) # Attach date of upload to transformed file\nwrite_csv(df_nfl_t2, str_c(today(), \" BAL NfL from NACC Upload.csv\")) # Attach date of upload to transformed file\nwrite_csv(df_gfap_t2, str_c(today(), \" BAL GFAP from NACC Upload.csv\")) # Attach date of upload to transformed file\n\n# api_upload &lt;- str_c(read_lines(\"file.csv\"), collapse = \"\\n\")\n#\n# return &lt;- RCurl::postForm(\n#   uri=REDCAP_API_URI,\n#   token=REDCAP_API_TOKEN_UMMAPGENERAL,\n#   content='record',\n#   format='csv',\n#   type='flat',\n#   overwriteBehavior='normal',\n#   # fields=upload_fields,\n#   data=api_upload\n# )"
  },
  {
    "objectID": "assets/team_bios/jon_reader.html",
    "href": "assets/team_bios/jon_reader.html",
    "title": "Jon Reader",
    "section": "",
    "text": "Jon Reader, Data Systems Manager\n\n\n\n\nJon joined the Michigan Alzheimer’s Disease Center in the summer of 2019 as a Data Analyst/Programmer as part of Data Core. In 2021, he became the Data Core Manager. Jon earned his M.S in Human Development and Family Studies from The Pennsylvania State University in 2015. Jon’s role in the data core includes supervising the Data Core team, working with other Core managers, center-affiliated investigators, other centers, and the National Alzheimer’s Coordinating Center. Jon is a center resource for pointing technical and statistical questions to appropriate team members. Jon is currently working on expanding his expertise into proper project management skills/techniques and taking pictures of his cats.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "assets/team_bios/jenna_anderson.html",
    "href": "assets/team_bios/jenna_anderson.html",
    "title": "Jenna Anderson",
    "section": "",
    "text": "Jenna Anderson, Graduate Student Summer Intern\n\n\n\n\nJenna Joined the Michigan Alzheimer’s Disease Center in the summer of 2023 and was a member of the Clinical Core until the Fall of 2024 when she joined the Data Core as a Graduate Student Summer Intern. She earned her B.S. in Psychology from Virginia Commonwealth University in 2018 and is currently obtaining her MPH in Epidemiology at the University of Michigan. Jenna’s role in data core includes: prepping and handling visit packets for various studies, entering data into REDCap, and various other small projects. Reach out to Jenna if you have any questions regarding participant visits or specific visit questions. In her free time, Jenna loves to play different sports, like soccer and judo, and enjoys traveling.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "assets/team_bios/subhamoy_pal.html",
    "href": "assets/team_bios/subhamoy_pal.html",
    "title": "Subhamoy Pal",
    "section": "",
    "text": "Subhamoy Pal, Statistician\n\n\n\n\nSubhamoy has been working as a Statistician on the Data Management and Statistical Core of the Michigan Alzheimer’s Disease Research Center since Aug, 2022. Subhamoy has expertise in neuropsychological data analysis and analyses of Alzheimer’s disease and related dementia biomarkers. His role is working across various clinical, observational, and trial projects with repeated measures for data analysis and cognitive assessments. As a biostatistician, his journey in medical and health care research reflects both a professional interest and personal preference. He completed a PhD in Statistics from Bowling Green State University, where he developed methods for improving power for the Cox proportional Hazards Model. He received training from several excellent professors during his academic career and developed analytic skills, specifically in the areas of clinical trials and clinical study research, missing data, and Intraclass correlation.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "assets/team_bios/ghadeer_ankouni.html",
    "href": "assets/team_bios/ghadeer_ankouni.html",
    "title": "Ghadeer Ankouni",
    "section": "",
    "text": "Ghadeer Ankouni, Data Entry Specialist\n\n\n\n\nGhadeer has been with the Michigan Alzheimer’s Disease Center since February of 2023 as a member of Data Core as a Data Entry Specialist. She earned her B.S. in Psychology from Eastern Michigan University in December of 2021. Ghadeer’s role in the data core includes entering data from various visits and studies, working alongside other cores to ensure the data is accurate, as well as prepping and handling study visit packets. Reach out to Ghadeer for any questions regarding REDCap, participant visits, or specific visit questions. In her free time, Ghadeer loves to bake and create her own recipes!\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "assets/team_bios/tj_rogers.html",
    "href": "assets/team_bios/tj_rogers.html",
    "title": "T.J. Rogers",
    "section": "",
    "text": "T.J. Rogers, Database Administrator\n\n\n\n\nT.J. joined the MADC in the winter of 2023 as a Database Administrator. Holding a M.S. in Information Systems from Murray State University, he plays a key role in preparing data for consensus conference meetings. He is also responsible for digitizing and organizing paper records for a large registry of longitudinal studies. Beyond his professional experience, he usually spends his time staying current with technology trends and expanding his knowledge of business and personal finance.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Established at Michigan Medicine and based in the Department of Neurology, the Michigan Alzheimer’s Disease Center aims to:\n\nConduct and support research on Alzheimer’s disease and related dementias\nPromote state-of-the-art care and wellness for individuals and families affected by memory loss\nIncrease dementia awareness through collaborative education and outreach efforts\nProvide training and support to the next generation of clinicians and scientists"
  },
  {
    "objectID": "about.html#the-michigan-alzheimers-disease-center",
    "href": "about.html#the-michigan-alzheimers-disease-center",
    "title": "About",
    "section": "",
    "text": "Established at Michigan Medicine and based in the Department of Neurology, the Michigan Alzheimer’s Disease Center aims to:\n\nConduct and support research on Alzheimer’s disease and related dementias\nPromote state-of-the-art care and wellness for individuals and families affected by memory loss\nIncrease dementia awareness through collaborative education and outreach efforts\nProvide training and support to the next generation of clinicians and scientists"
  },
  {
    "objectID": "about.html#meet-the-data-core",
    "href": "about.html#meet-the-data-core",
    "title": "About",
    "section": "Meet the Data Core",
    "text": "Meet the Data Core\nThe Data Management and Statistical Core (Data Core), led by Kelly Bakulski, PhD, helps maintain our center’s academic and research productivity by integrating and disseminating data to our research investigators. The data core manages data privacy, analyzes data for specific research projects, and facilitates data sharing nationally with the National Alzheimer’s Coordinating Center.\n\n\nFaculty Leadership\n\n\n Kelly Bakulski, PhD\nData Management and Statistical Core Leader and\nAssociate Professor, Epidemiology, University of Michigan School of Public Health\n\n\n Ana Daugherty, PhD\nData Management and Statistical Core Affiliated Faculty and\nAssociate Professor, Institute of Gerontology, Wayne State University\n\n\n\n\n\n Jian Kang, PhD, MS\nData Management and Statistical Core Affiliated Faculty,\nAssociate Chair for Research, and\nProfessor of Biostatistics, University of Michigan School of Public Health\n\n\n\n\n\nStaff Leadership\n\n\n Jon Reader\nData Systems Manager\n\n\n\n\n\nData Integrity\n\n\n Ghadeer Ankouni\nData Entry Specialist\n\n\n Haley Payne\nResearch Assistant\n\n\n\n\n\n T.J. Rogers\nDatabase Administrator\n\n\n\n\n\nProgramming and Analysis\n\n\n Kenneth Petscavage\nData Analyst / Programmer\n\n\n Miranda Cooper\nData Analyst / Programmer\n\n\n\n\n\n Subhamoy Pal\nStatistician\n\n\n\n\n\nStudent Interns\n\n\n Jenna Anderson\nGraduate Student Summer Intern"
  },
  {
    "objectID": "codebases.html",
    "href": "codebases.html",
    "title": "Codebases",
    "section": "",
    "text": "This page provides access to code-based protocols developed by the Michigan Alzheimer’s Disease Center’s (MADC) Data Core. These resources include GitHub repositories and Quarto documents outlining our workflows for data management, processing, and analysis.\nWhile underlying data are not shared, these codebases reflect the tools and logic we use locally to support research operations and maintain data integrity across projects.\n\n\n\n\n\n\nNote\n\n\n\nStay tuned: Additional code protocols and tools will be added as they are finalized.\n\n\n\n\n\n\n\n\n\n\n\n\n\nUpload Biomarker and Longitudinal (BAL) data to REDCap system\n\n\n\nR\n\nQuarto\n\nREDCap\n\nNACC\n\n\n\nA protocol for uploading Biomarker and Longitudinal (BAL) data returned from the National Alzheimer’s Coordinating Center (NACC) into the REDCap system.\n\n\n\n\n\nauthors\n\n\nJonathan M. Reader\n\n\n\n\n\n\n\n\nNo matching items\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Michigan Alzheimer’s Disease Research Center",
    "section": "",
    "text": "The Michigan Alzheimer’s Disease Research Center (MADRC) Data Core Sharing Hub is a public platform dedicated to supporting Alzheimer’s disease and related dementias research through the dissemination of data, analytic tools, and knowledge.\nThis website is created and maintained by the Data Management and Statistical Core (Data Core) at the MADRC. The MADRC is a statewide, multi-university collaboration between the University of Michigan, Wayne State University, and Michigan State University housed at the Michigan Alzheimer’s Disease Center (MADC) at the University of Michigan Medical School. The MADRC Data Core Sharing Hub highlights the impactful work of our team and reflects our commitment to fostering collaboration and innovation in Alzheimer’s research. The MADRC is grateful for financial support from the National Institute on Aging (P30 AG072931).\n\n\n\n\n\n\n\n\n\nExplore our resources and discover how the MADRC Data Core contributes to advancing knowledge and improving care for those affected by Alzheimer’s disease and their communities."
  },
  {
    "objectID": "index.html#data-sharing-hub",
    "href": "index.html#data-sharing-hub",
    "title": "Michigan Alzheimer’s Disease Research Center",
    "section": "",
    "text": "The Michigan Alzheimer’s Disease Research Center (MADRC) Data Core Sharing Hub is a public platform dedicated to supporting Alzheimer’s disease and related dementias research through the dissemination of data, analytic tools, and knowledge.\nThis website is created and maintained by the Data Management and Statistical Core (Data Core) at the MADRC. The MADRC is a statewide, multi-university collaboration between the University of Michigan, Wayne State University, and Michigan State University housed at the Michigan Alzheimer’s Disease Center (MADC) at the University of Michigan Medical School. The MADRC Data Core Sharing Hub highlights the impactful work of our team and reflects our commitment to fostering collaboration and innovation in Alzheimer’s research. The MADRC is grateful for financial support from the National Institute on Aging (P30 AG072931).\n\n\n\n\n\n\n\n\n\nExplore our resources and discover how the MADRC Data Core contributes to advancing knowledge and improving care for those affected by Alzheimer’s disease and their communities."
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resource Library",
    "section": "",
    "text": "Curated by the Michigan Alzheimer’s Disease Center’s (MADC) Data Core, this resource library offers a growing collection of tools, tutorials, and references designed to support both new and current staff in building technical skills that enhance the Center’s daily operations. You can explore the full list below or click on a category in the right-hand sidebar to filter resources by topic.\nFeedback and Suggestions\nWe welcome your input! If you have suggestions for additional resources or general feedback about the library, please submit them using this form. The Data Core team regularly reviews submissions and updates the library to ensure it remains current and relevant.\n\n\n\n\n\n\n\n\n\n\n\nCommand Line for Beginners – How to Use the Terminal Like a Pro\n\n\n\nCommand-line Interface\n\n\n\nAn article from freeCodeCamp that explains the various parts of the command line interface and the basics of how it works\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nArticle\n\n\n\n\n\n\n\n\n\n\n\n\nThe Linux Command Line\n\n\n\nCommand-line Interface\n\n\n\nA book, written with the new command line user in mind, which includes the basics of command line use and shell scripting. Check out the corresponding website…\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nBook\n\n\n\n\n\n\n\n\n\n\n\n\nThe Art of Command Line\n\n\n\nCommand-line Interface\n\n\n\nA guide that provides an overview of interactive Bash for Linux with two sections that include additional guidance for macOS and Windows users\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nGuide\n\n\n\n\n\n\n\n\n\n\n\n\nCommand Line Fundamentals\n\n\n\nCommand-line Interface\n\n\n\nMaster shell basics and Unix tools and discover easy commands to perform complex tasks with speed\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nBook\n\n\n\n\n\n\n\n\n\n\n\n\nTabiew\n\n\n\nCommand-line Interface\n\nCommand-line Tools\n\n\n\nTabiew is a lightweight, terminal-based application to view and query delimiter separated value formatted documents, such as CSV and TSV files\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTool\n\n\n\n\n\n\n\n\n\n\n\n\nemphatic\n\n\n\nCommand-line Interface\n\nCommand-line Tools\n\n\n\n{emphatic} is a tool for exploratory analysis of tabular data. It allows the user to visually colour elements of the data, yet still keep all values visible\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTool\n\n\n\n\n\n\n\n\n\n\n\n\nUniversity of Michigan ITS AI Services\n\n\n\nGenerative AI\n\n\n\nUM’s ITS team is now offering a generative AI platform and these service offerings are equitable, accessible, and support everything from basic consumer usage to advanced…\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nArticle\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative AI for Beginners (Version 2) - A Course\n\n\n\nGenerative AI\n\n\n\nLearn the fundamentals of building Generative AI applications with an 18-lesson comprehensive course by Microsoft Cloud Advocates\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCourse\n\n\n\n\n\n\n\n\n\n\n\n\nPro Git book\n\n\n\nGit\n\nGitLab\n\n\n\nLearn git at your own pace with the Pro Git Book, managed by the git community\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBook\n\n\n\n\n\n\n\n\n\n\n\n\nGit Cheatsheet by GitLab\n\n\n\nGit\n\nGitLab\n\n\n\nQuick reference guide for important Git commands, created by GitLab\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCheatsheet\n\n\n\n\n\n\n\n\n\n\n\n\nGit Cheatsheet by Atlassian\n\n\n\nGit\n\n\n\nA handy git cheat sheet guide to enhance your workflow, created by Atlassian\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCheatsheet\n\n\n\n\n\n\n\n\n\n\n\n\nGit Cheatsheet by GitHub\n\n\n\nGit\n\nGitHub\n\n\n\nQuick reference guide for important Git commands, created by GitHub\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCheatsheet\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Git: Git version control software with RStudio\n\n\n\nGit\n\nRStudio\n\n\n\nA recorded workshop on Git version control software with RStudio from the University of Michigan Biostatistics department\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Git with RStudio\n\n\n\nGit\n\nRStudio\n\n\n\nQuick reference step-by-step tutorial on setting up git with RStudio\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nGit Learning Videos\n\n\n\nGit\n\n\n\nLinks to some basic tutorial videos created by the git maintainer community\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nLearn Git on the Command Line\n\n\n\nGit\n\nCommand-line Interface\n\n\n\nA playlist of YouTube videos prepared by Tower, a git client for macOS and Windows\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nVersion Control with Git\n\n\n\nGit\n\nVersion Control\n\n\n\nAn online beginner course, developed by Software Carpentry, teaching the basics of version control with Git\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCourse\n\n\n\n\n\n\n\n\n\n\n\n\nInteractive Git Cheatsheet\n\n\n\nGit\n\n\n\nAn interactive Git Cheatsheet, developed by NDP Software, that visually represents git commands and states\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCheatsheet\n\n\n\n\n\n\n\n\n\n\n\n\nConfusing git terminology\n\n\n\nGit\n\n\n\nA blog entry from Julia Evans, a software developer, which walks through various git terms that tend to confuse users\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBlog\n\n\n\n\n\n\n\n\n\n\n\n\nLearn GitLab with Pj: A Walkthrough and Explanation\n\n\n\nGitLab\n\n\n\nOverview and walkthrough of GitLab Project basics by a member of the GitLab education team\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nGitLab Flavored Markdown (GLFM)\n\n\n\nGitLab\n\nMarkdown\n\n\n\nOverview of styling and syntax for GitLab’s version of Markdown\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nDocumentation\n\n\n\n\n\n\n\n\n\n\n\n\nUse the left sidebar to navigate GitLab\n\n\n\nGitLab\n\n\n\nA walk-through of GitLab’s navigation in the left-hand sidebar\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nLearning GitLab\n\n\n\nGitLab\n\n\n\nA (1h 3m) LinkedIn Learning tutorial with an overview of basic GitLab UI and functionality\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is Version Control? [Learn Git Video Course]\n\n\n\nVersion Control\n\nGit\n\nSource Code Management\n\n\n\nA short video reviewing the basics of version control and why to use it\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nGitLab Branching Strategy | GitLab Flow Tutorial Part 1\n\n\n\nGitLab\n\nVersion Control\n\nGit\n\nSource Code Management\n\n\n\nA (15 min) tutorial discussing GitLab Flow and a conceptual overview of strategies for working with Git\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nDescribe productivity solutions of Microsoft 365\n\n\n\nMicrosoft 365\n\nProductivity\n\n\n\nLearn about how the productivity solutions through Microsoft 365 help optimize operations, enhance content creation, and empower people to perform tasks in real-time from…\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nModule\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Power Automate Desktop for Developers\n\n\n\nMicrosoft 365\n\nPower Automate\n\n\n\nA (1h 45m) introductory course on getting started with Power Automate Desktop.\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nManaging Data with Microsoft 365\n\n\n\nMicrosoft 365\n\nData Management\n\n\n\nA (1h 3m) overview course on managing data with Microsoft Forms, Excel, Power Automate, and Power BI\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nPresent your data in a Gantt chart in Excel\n\n\n\nMicrosoft 365\n\nGantt\n\nProject Visualization\n\n\n\nMicrosoft 365 subscription offers premium Gantt chart templates designed to help you track project tasks with visual reminders and color-coded categories\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nGet organized with Gantt chart templates\n\n\n\nMicrosoft 365\n\nGantt\n\n\n\nA listing of Gantt chart templates for Excel\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTemplates\n\n\n\n\n\n\n\n\n\n\n\n\nUse a wizard to create a Gantt Chart\n\n\n\nMicrosoft Project\n\nMicrosoft 365\n\nGantt\n\n\n\nSpecific to Microsoft Project, which includes a wizard to walk through the creation of a Gantt chart\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding a Gantt Chart using Power BI\n\n\n\nMicrosoft 365\n\nPower BI\n\nGantt\n\n\n\nA step-by-step guide on loading an excel sheet into Power BI to create a Gantt chart\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nSet up a basic Gantt chart in Excel\n\n\n\nMicrosoft 365\n\nGantt\n\n\n\nA 10 minute video walking through the process of a setting up a Gantt chart using Excel\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Excel for Gantt charts: My top 10 tips\n\n\n\nMicrosoft 365\n\nGantt\n\n\n\nA quick 4 minute video with pro tips on using Excel for Gantt charts\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nManaging Projects with Microsoft 365\n\n\n\nMicrosoft 365\n\nProject Management\n\n\n\nA (49m) overview course on managing project using Microsoft Lists, Planner, and Project\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nMicrosoft Planner Essential Training\n\n\n\nMicrosoft 365\n\nMicrosoft Planner\n\nProject Management\n\n\n\nA (1h 27m) Linkedin Learning course on the essential features of Microsoft Planner\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nPEP 8 – Style Guide for Python Code\n\n\n\nPython\n\n\n\nThis document gives coding conventions for Python code comprising the standard library in the main Python distribution\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nDocumentation\n\n\n\n\n\n\n\n\n\n\n\n\nPython Tutor\n\n\n\nPython\n\n\n\nThe Python Tutor is a unique step-by-step visual debugger and AI tutor to help you understand and debug code\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nPython for Everybody\n\n\n\nPython\n\n\n\nThis web site is building a set of free materials, lectures, book and assignments to help students learn how to program in Python\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCourse\n\n\n\n\n\n\n\n\n\n\n\n\nPython Virtual Environments\n\n\n\nPython\n\n\n\nA quick guide for setting up Python virtual environments on macOS and Windows 10\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nFluent Python\n\n\n\nPython\n\n\n\nA hands-on guide walking through how to write effective, modern Python 3 code by leveraging its core language features and libraries\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\npandas Documentation\n\n\n\nPython\n\nData Wrangling\n\nPandas\n\n\n\npandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nDocumentation\n\n\n\n\n\n\n\n\n\n\n\n\nThink Python: How to Think Like a Computer Scientist\n\n\n\nPython\n\n\n\nA textbook that teaches Python through the lens of a computer scientist, utilizing the best features from mathematics, engineering, and natural science\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nProgramming with Python\n\n\n\nPython\n\n\n\nAn online beginner course, developed by Software Carpentry, introducing the basics of Python programming through data analysis\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCourse\n\n\n\n\n\n\n\n\n\n\n\n\nData Analysis with Pandas and Python\n\n\n\nPython\n\nPandas\n\nData Analysis\n\nData Wrangling\n\n\n\nA text that introduces you to the popular Pandas library built on top of the Python programming language\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nPython for Data Analysis, 3rd Edition\n\n\n\nPython\n\nData Analysis\n\n\n\nA definitive handbook for manipulating, processing, cleaning, and crunching datasets in Python\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nPandas for Everyone: Python Data Analysis, 2nd Edition\n\n\n\nPython\n\nPandas\n\nData Analysis\n\nData Wrangling\n\n\n\nA text providing practical knowledge and insight for solving real problems with pandas, even for those new to Python data analysis\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nPython Data Science Handbook, 2nd Edition\n\n\n\nPython\n\nData Analysis\n\n\n\nA handbook for scientific computing in Python that highlights the data science stack - IPython, NumPy, pandas, Matplotlib, Scikit-Learn, and other related tools\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Data Visualization in Python\n\n\n\nPython\n\nData Visualization\n\n\n\nAn article with quick tutorials on visualizing data with Python in Matplotlib, Pandas, and Seaborn\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nA Complete Guide to Data Visualization in Python With Libraries & More\n\n\n\nPython\n\nData Visualization\n\n\n\nA (1h 54m) video with transcription which reviews the basics of data visualization in Python with Matplotlib and Seaborn\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nGreat Tables: Absolutely Delightful Table-making in Python\n\n\n\nPython\n\nData Visualization\n\n\n\nDocumentation for the Great Tables Python package that makes it easy to generate information-rich, publication-quality tables. The package leverages pandas and polars…\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nDocumentation\n\n\n\n\n\n\n\n\n\n\n\n\npolars’ Rgonomic Patterns\n\n\n\nPython\n\nPolars\n\nData Wrangling\n\n\n\nA blog post highlighting the advanced data wrangling functionality in python’s polars package to see how it mirrors dplyr and tidyr’s syntax\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBlog\n\n\n\n\n\n\n\n\n\n\n\n\nProgramming with R\n\n\n\nR\n\nProgramming\n\n\n\nAn online beginner course, developed by Software Carpentry, introducing the basics of R programming through data analysis\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCourse\n\n\n\n\n\n\n\n\n\n\n\n\nR for Reproducible Scientific Analysis\n\n\n\nR\n\nData Analysis\n\nReproducibility\n\n\n\nAn online beginner course, developed by Software Carpentry, introducing the basics of R programming through analysis of the gapminder data\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCourse\n\n\n\n\n\n\n\n\n\n\n\n\nBase R Cheat Sheet from Posit\n\n\n\nR\n\n\n\nA quick reference guide (downloadable pdf) of basic syntax and functionality in R\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCheatsheet\n\n\n\n\n\n\n\n\n\n\n\n\nR for Data Science: Analysis and Visualization\n\n\n\nR\n\nData Analysis\n\nData Visualization\n\n\n\nAn introducty LinkedIn Learning course (2h 46m) on the basics of getting started with R for data visualization, wrangling, and analysis\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nQuick-R\n\n\n\nR\n\n\n\nSite containing a broad overview of R resources for learning R created by a statistical consultant and research methodologist\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to R and RStudio\n\n\n\nR\n\nRStudio\n\n\n\nA recorded workshop on workflow basics, scripts, and projects from the University of Michigan Biostatistics department\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nR Essential Training: Wrangling and Visualizing Data\n\n\n\nR\n\nData Visualization\n\nData Wrangling\n\n\n\nAn introductory LinkedIn Learning course (4h 18m) on the essential tools for importing visualizing, and wrangling data in R\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nBig Book of R\n\n\n\nR\n\n\n\nA listing of over 300 Reference books on the R programming language\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nTidy design principles\n\n\n\nR\n\nTidyverse\n\n\n\nStill under development, this book identifies challenges and patterns to help you write better R code. There is also a related Tidy Design Princiles blog/newsletter that the…\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBook\n\n\n\n\n\n\n\n\n\n\n\n\nThe tidyverse style guide\n\n\n\nR\n\nTidyverse\n\n\n\nA site that site describes the style used throughout the tidyverse, written by Hadley Wickham of Posit\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBook\n\n\n\n\n\n\n\n\n\n\n\n\n23 RStudio Tips, Tricks, and Shortcuts\n\n\n\nR\n\nRStudio\n\n\n\nA blog post covering some of the best features of RStudio with a list of tips, tricks, and shortcuts\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBlog\n\n\n\n\n\n\n\n\n\n\n\n\nWhat They Forgot to Teach You About R\n\n\n\nR\n\nData Analysis\n\n\n\nThis book focuses on content intrinsically related to the infrastructure surrounding data analysis in R, but does not delve into the data analysis itself\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBook\n\n\n\n\n\n\n\n\n\n\n\n\nR for the Rest of Us: A Statistics-Free Introduction\n\n\n\nR\n\nRStudio\n\n\n\nA crash course in R, a quick tour of the RStudio programming environment, and a collection of real-word applications that you can put to use right away\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nBook\n\n\n\n\n\n\n\n\n\n\n\n\nR for Data Science (2e)\n\n\n\nR\n\nTidyverse\n\nData Analysis\n\nData Visualization\n\n\n\nFREE 2nd edition of ‘R for Data Science’ which provides practical skills for data science, including data importation, data structuring, data transformation, and data…\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nStatistical Inference via Data Science: A ModernDive into R and the Tidyverse\n\n\n\nR\n\nStatistics\n\nTidyverse\n\n\n\nThe companion website to Chester Ismay and Albert Y. Kim’s introductory statistics textbook, which walks students through the entire data analysis pipeline using R and…\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nR Screencasts\n\n\n\nR\n\nData Analysis\n\n\n\nLive data analysis screencasts from a top Data Scientist, David Robinson\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nTools for Analyzing R Code the Tidy Way\n\n\n\nR\n\nTidyverse\n\n\n\nAn article on two packages, matahari and tidycode, written to analyze R code in a tidy manner\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nArticle\n\n\n\n\n\n\n\n\n\n\n\n\nTidy Modeling with R\n\n\n\nR\n\nData Modeling\n\nTidymodels\n\n\n\nA guide to using a collection of software in the R programming language for model building called tidymodels\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nR Markdown Cookbook\n\n\n\nR\n\nMarkdown\n\n\n\nThis book is broken down into small ‘recipes’ that aim to demonstrate a single R Markdown concept at a time.\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nR Markdown: The Definitive Guide\n\n\n\nR\n\nMarkdown\n\n\n\nThis book is a definitive reference guide to the R Markdown language\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nR Markdown Tips, Tricks, and Shortcuts\n\n\n\nR\n\nMarkdown\n\nRStudio\n\n\n\nA blog post with some helpful tips and tricks for working with R Markdown in RStudio\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBlog\n\n\n\n\n\n\n\n\n\n\n\n\nQuick list of useful R packages\n\n\n\nR\n\nR Packages\n\n\n\nA categorized list of recommended free libraries of code written by the active user community\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nCRAN Task Views\n\n\n\nR\n\n\n\nComprehensive R Archive Network (CRAN)‘s listing of packages by topic area or ’task’\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nggplot2 Cheatsheet by Posit\n\n\n\nR\n\nGgplot2\n\nData Visualization\n\n\n\nA quick reference guide for basic syntax and functionality of the data visualization ggplot2 package, including a downloadable pdf\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCheatsheet\n\n\n\n\n\n\n\n\n\n\n\n\nrmarkdown Cheatsheet by Posit\n\n\n\nR\n\nMarkdown\n\n\n\nA quick reference guide for basic syntax and functionality of the authoring framework rmarkdown, including a downloadable pdf\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCheatsheet\n\n\n\n\n\n\n\n\n\n\n\n\ntidyverse Cheatsheet by Posit\n\n\n\nR\n\nTidyverse\n\n\n\nA quick reference guide for basic syntax and functionality of the data science packages that comprise the tidyverse, including a downloadable pdf\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCheatsheet\n\n\n\n\n\n\n\n\n\n\n\n\ndplyr Cheatsheet by Posit\n\n\n\nR\n\nDplyr\n\nData Wrangling\n\n\n\nA quick reference guide for basic syntax and functionality of the data manipulation dplyr package, including a downloadable pdf\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCheatsheet\n\n\n\n\n\n\n\n\n\n\n\n\ntidyr Cheatsheet by Posit\n\n\n\nR\n\nTidyr\n\nData Cleaning\n\n\n\nA quick reference guide for basic syntax and functionality of the data cleaning tidyr package, including a downloadable pdf\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCheatsheet\n\n\n\n\n\n\n\n\n\n\n\n\nhtmlwidget\n\n\n\nR\n\nJavaScript\n\nData Visualization\n\n\n\nA package for creating JavaScript data visualizations in R\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nDocumentation\n\n\n\n\n\n\n\n\n\n\n\n\nreprex\n\n\n\nR\n\nReproducibility\n\n\n\nAn R package for preparing reproducible examples of R code\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nDocumentation\n\n\n\n\n\n\n\n\n\n\n\n\nReproducible research with R, RStudio and GitLab\n\n\n\nR\n\nGit\n\nGitLab\n\nRStudio\n\nReproducibility\n\n\n\nA manual describing easy reproducibility and collaboration with R and Git\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nDocumentation\n\n\n\n\n\n\n\n\n\n\n\n\nInstructions for Creating Your Own R Package\n\n\n\nR\n\nR Packages\n\n\n\nAn article with a step-by-step guide to creating your own R package\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nArticle\n\n\n\n\n\n\n\n\n\n\n\n\nWriting R Packages in RStudio\n\n\n\nR\n\nR Packages\n\nRStudio\n\nGitHub\n\n\n\nA tutorial walking through the set up of a basic R package that can be installed from GitHub\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nMaking Your First R Package\n\n\n\nR\n\nR Packages\n\n\n\nA blog entry that walks through the steps of organizing code in a package with consistent documentation\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBlog\n\n\n\n\n\n\n\n\n\n\n\n\nThe Package: learning how to build an R package\n\n\n\nR\n\nR Packages\n\n\n\nA blog entry from R-Bloggers that walks through the process of setting up an R package\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBlog\n\n\n\n\n\n\n\n\n\n\n\n\nWriting an R package from scratch\n\n\n\nR\n\nR Packages\n\n\n\nA blog entry from Hilary Parker of Etsy on setting up your first R package from scratch\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBlog\n\n\n\n\n\n\n\n\n\n\n\n\nCRAN documentation on Creating R packages\n\n\n\nR\n\nR Packages\n\n\n\nOriginal documentation on how to create an R package from the Comprehensive R Archive Network (CRAN)\n\n\n\n\n\nSkill Level\n\n\nAdvanced\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nR Packages (2e)\n\n\n\nR\n\nR Packages\n\nReproducibility\n\n\n\nLearn how to create a package, the fundamental unit of shareable, reusable, and reproducible R code from Hadley Wickham and Jennifer Bryan of Posit\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nThe R Graph Gallery\n\n\n\nR\n\nData Visualization\n\n\n\nA collection of R’s available chart types listed by purpose, and including guidance on required packages and syntax\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nData Visualization in R With ggplot2\n\n\n\nR\n\nGgplot2\n\nData Visualization\n\n\n\nA video course on how to create great looking, insightful data visualizations using the R package, ggplot2\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nColor in Data Vis\n\n\n\nData Visualization\n\n\n\nA feed of blog entries on the selection of beautiful, legible colors in data visualization, charts, and maps\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBlog\n\n\n\n\n\n\n\n\n\n\n\n\nExciting Data Visualizations with ggplot2 Extensions\n\n\n\nR\n\nGgplot2\n\nData Visualization\n\n\n\nA (1h 28m) presentation by Cédric Scherer diving into the world of data visualization and the art of creating engaging and effective data graphics with ggplot2\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nPsychology of Data Visualization\n\n\n\nR\n\nData Visualization\n\n\n\nAn online self-paced course that examines a variety of issues related to data visualization from a largely psychological perspective, including an overview of ggplot2\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCourse\n\n\n\n\n\n\n\n\n\n\n\n\nModern Data Visualization with R\n\n\n\nR\n\nData Visualization\n\n\n\nA helpful and user-friendly book that walks through creating the most popular visualizations — from quick and dirty plots to publication-ready graphs\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBook\n\n\n\n\n\n\n\n\n\n\n\n\ntidyexplain\n\n\n\nR\n\nTidyverse\n\nData Wrangling\n\n\n\nAnimations of tidyverse verbs using R, the tidyverse, and gganimate\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling with R\n\n\n\nR\n\nData Wrangling\n\nTidyverse\n\n\n\nA text for all levels of R programmers, covering the various data wrangling packages: dplyr, tidyr, httr, stringr, lubridate, readr, rvest, magrittr, xlsx, readxl, and others\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling in R\n\n\n\nR\n\nData Wrangling\n\n\n\nA (2h 51m) LinkedIn Learning course that provides an overview of data wrangling techniques for cleaning and transforming data\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to the Tidyverse\n\n\n\nR\n\nTidyverse\n\nData Wrangling\n\n\n\nA recorded workshop on the tidyverse and visualizing data in ggplot2 from the University of Michigan Biostatistics department\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nLearning the R Tidyverse\n\n\n\nR\n\nTidyverse\n\nData Wrangling\n\n\n\nA (3h 50m) LinkedIn Learning course walking through the tidyverse approach to data science\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nThe Quartz Guide to Bad Data\n\n\n\nR\n\nData Wrangling\n\nData Cleaning\n\n\n\nThis guide presents thorough descriptions and suggested solutions to many of the kinds of problems that you will encounter when working with data\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing {dplyr}’s mutate(), summarize(), group_by(), and ungroup() with animations\n\n\n\nR\n\nDplyr\n\nData Wrangling\n\n\n\nVisually explore how {dplyr}’s more complex core functions work together to wrangle data\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nArticle\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to R with Tidyverse\n\n\n\nR\n\nTidyverse\n\nData Wrangling\n\n\n\nThis course is a gentle introduction to the RStudio interface and provides the basics of the R coding language and syntax. This course is ideal for beginners with little or…\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCourse\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Programming in R\n\n\n\nR\n\nProgramming\n\n\n\nA recorded workshop on functions, vectors, and iteration in R from the University of Michigan Biostatistics department\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nEfficient R Programming\n\n\n\nR\n\nProgramming\n\n\n\nA textbook for all skill levels on making R code faster, more efficient, and scalable\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nHands-On Programming with R\n\n\n\nR\n\nProgramming\n\n\n\nThis book will teach you how to program in R, with hands-on examples.\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced R\n\n\n\nR\n\nProgramming\n\n\n\nAn advanced textbook on metaprogramming or the idea that code is data that can be inspected and modified programmatically\n\n\n\n\n\nSkill Level\n\n\nAdvanced\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nR Programming for Data Science\n\n\n\nR\n\nProgramming\n\nData Analysis\n\n\n\nThis book is about the fundamentals of R programming. With the fundamentals provided in this book, you will have a solid foundation on which to build your data science…\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nRegex101\n\n\n\nRegular Expressions\n\n\n\nHelpful online tool for learning, building, and matching regular expressions to a test string\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTool\n\n\n\n\n\n\n\n\n\n\n\n\nRegExr\n\n\n\nRegular Expressions\n\n\n\nHelpful online tool for learning, building, and matching regular expressions to a test string\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTool\n\n\n\n\n\n\n\n\n\n\n\n\nRegexOne\n\n\n\nRegular Expressions\n\n\n\nAn interactive tutorial with simple exercises for learning regular expressions\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nRegexLearn\n\n\n\nRegular Expressions\n\n\n\nA step-by-step tutorial for practicing regular expressions\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nRegexLearn Cheatsheet\n\n\n\nRegular Expressions\n\n\n\nQuick reference guide for regex syntax\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCheatsheet\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Regular Expressions\n\n\n\nRegular Expressions\n\n\n\nA (3h 18m) LinkedIn Learning course with a broad overview of regular expressions\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nPythex\n\n\n\nRegular Expressions\n\nPython\n\n\n\nHelpful interactive tool for testing Python regular expressions\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTool\n\n\n\n\n\n\n\n\n\n\n\n\nSQL Tutorial\n\n\n\nSQL\n\n\n\nA self-paced tutorial, by w3schools, that walks through basic SQL commands\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nSQL Keywords Reference\n\n\n\nSQL\n\n\n\nA quick reference list of the reserved words in SQL\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nSQLZoo Tutorial\n\n\n\nSQL\n\n\n\nA step by step tutorial reviewing the basics of SQL queries\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nPractical SQL, 2nd Edition\n\n\n\nSQL\n\n\n\nAn approachable and fast-paced guide to SQL (Structured Query Language), the standard programming language for defining, organizing, and exploring data in relational…\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nBook\n\n\n\n\n\n\n\n\n\n\n\n\nLearn SQL\n\n\n\nSQL\n\n\n\nA free self-paced course, developed by codecademy, which demonstrates how to manage large datasets and analyze real data using standard data management language\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCourse\n\n\n\n\n\n\n\n\n\n\n\n\nSQLBolt: Introduction to SQL\n\n\n\nSQL\n\n\n\nA series of interactive lessons and exercises designed to help you quickly learn SQL in your browser\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCourse\n\n\n\n\n\n\n\n\n\n\n\n\nSQL join flavors\n\n\n\nSQL\n\n\n\nAn article that explores various types of SQL joins, including helpful visualizations for each\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nArticle\n\n\n\n\n\n\n\n\n\n\n\n\nThe Querynomicon: An Introduction to SQL for the Cautious and Weary\n\n\n\nSQL\n\n\n\nA tutorial with notes and working examples for various SQL and database functions\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nSQL Style Guide\n\n\n\nSQL\n\nProgramming\n\n\n\nA SQL syntax guide designed to be compatible with Joe Celko’s SQL Programming Style book\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nSQL Polyglot\n\n\n\nSQL\n\n\n\nA browser-based tool for checking if a particular SQL feature is supported in various database systems\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nTool\n\n\n\n\n\n\n\n\n\n\n\n\nInstitute for Social Research (ISR) Population Dynamics and Health Program Workshops\n\n\n\nStatistics\n\n\n\nA listing of past virtual workshops on various statistical techniques\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nConsulting for Statistics, Computing, & Analytics Research (CSCAR) Workshops\n\n\n\nStatistics\n\nData Analysis\n\n\n\nA listing of upcoming in-person workshops on various statistical techniques\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nEvents\n\n\n\n\n\n\n\n\n\n\n\n\nStatistical Inference via Data Science: A ModernDive into R and the Tidyverse\n\n\n\nStatistics\n\nR\n\n\n\nThe companion website to Chester Ismay and Albert Y. Kim’s introductory statistics textbook, which walks students through the entire data analysis pipeline using R and…\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nStatistics Course for Data Science\n\n\n\nStatistics\n\nData Analysis\n\n\n\nThe Statistics for Data Science Course covers statistical concepts taught in many intro and intermediate statistics courses in universities and colleges\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nThink Stats: Exploratory Data Analysis in Python\n\n\n\nStatistics\n\nPython\n\nData Analysis\n\n\n\nThis text is an introduction to the practical tools of exploratory data analysis\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTextbook\n\n\n\n\n\n\n\n\n\n\n\n\nProbably Overthinking It: Data Science and Bayesian Statistics\n\n\n\nStatistics\n\nData Analysis\n\n\n\nA blog series by Allen Downey, a curriculum designer at Brilliant, professor emeritus at Olin College, and author of Think Python, Think Bayes, and other books\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBlog\n\n\n\n\n\n\n\n\n\n\n\n\n50 years of Data Science\n\n\n\nStatistics\n\nData Analysis\n\n\n\nAn article based on a presentation from the 2015 Tukey Centennial workshop reviewing the last 50 years of Data Science and its emergence from the fields of statistics and…\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nArticle\n\n\n\n\n\n\n\n\n\n\n\n\nLessons in Statistical Thinking\n\n\n\nStatistics\n\n\n\nLessons in Statistical Thinking presents the statistical ideas and methods behind decision-making to guide action\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBook\n\n\n\n\n\n\n\n\n\n\n\n\nTableau for Data Scientists\n\n\n\nTableau\n\nData Analysis\n\n\n\nA (5h 55m) LinkedIn Learning course on how to visualize data in Tableau through a Data Science lens\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nCreating Interactive Tableau Dashboards\n\n\n\nTableau\n\nData Visualization\n\n\n\nA (3h 28m) LinkedIn Learning course on how to create interactive dashboards in Tableau\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nTableau and R for Analytics Projects\n\n\n\nTableau\n\nR\n\nData Analysis\n\nData Visualization\n\n\n\nA (2h 27m) LinkedIn Learning course on visualizing data with Tableau and R\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nIT4U91: 50 Tableau Tips\n\n\n\nTableau\n\nData Visualization\n\n\n\nA (40m) video on techniques and tips for building Tableau visualizations from the University of Michigan’s ITS department\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nIT4U79: Tiled Dashboards Design in Tableau\n\n\n\nTableau\n\nData Visualization\n\n\n\nA (43m) video on building a dashboard layout in Tableau by the University of Michigan’s ITS department\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nData Visualization Tips and Tricks\n\n\n\nTableau\n\nData Visualization\n\n\n\nA (2h 14m) LinkedIn Learning course giving guidance on basic data visualization\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nHow to name files by Jennifer Bryan of Posit\n\n\n\nDocumentation\n\n\n\nLow-tech common sense about filenames. The holy trinity is: machine readable, human readable, sorted in a useful way\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nThe Documentation System\n\n\n\nDocumentation\n\n\n\nA simple, comprehensive and nearly universally-applicable scheme for writing software documentation\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nDiátaxis technical documentation system\n\n\n\nDocumentation\n\n\n\nThis reference describes an information architecture that emerges from a systematic approach to understanding the needs of documentation users\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nHow To Write a Useful README for Your Next Project\n\n\n\nDocumentation\n\n\n\nAn article outlining the ‘must-haves’ for any project’s README file\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nArticle\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Started: An overview of Markdown…\n\n\n\nMarkdown\n\nDocumentation\n\n\n\nThe Markdown Guide is a comprehensive Markdown reference designed for both novices and experts\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nJohn Gruber’s Markdown documentation\n\n\n\nMarkdown\n\nDocumentation\n\n\n\nThe original Markdown documentation, written by the creator of Markdown\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nDocumentation\n\n\n\n\n\n\n\n\n\n\n\n\nMarkdown Tutorial\n\n\n\nMarkdown\n\nDocumentation\n\n\n\nA web-based walk-through of Markdown basics\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nAwesome Markdown\n\n\n\nMarkdown\n\nDocumentation\n\n\n\nA listing of Markdown libraries, services, editors, tools, cheatsheets, etc.\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nAwesome Quarto\n\n\n\nQuarto\n\nDocumentation\n\nMarkdown\n\n\n\nThe most up to date curated list of Quarto docs, talks, tools, examples & articles the internet has to offer\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nR Markdown Tips, Tricks, and Shortcuts\n\n\n\nMarkdown\n\nMarkdown\n\nDocumentation\n\n\n\nA blog post with some helpful tips and tricks for working with R Markdown in RStudio\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nBlog\n\n\n\n\n\n\n\n\n\n\n\n\nTrello Markdown Support\n\n\n\nMarkdown\n\nTrello\n\nDocumentation\n\n\n\nA reference chart that indicates which Markdown features are supported in Trello, along with a link to their syntax\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nHow to format your text in Trello\n\n\n\nMarkdown\n\nTrello\n\nDocumentation\n\n\n\nA quick guide to the keyboard shortcuts and Markdown features available in Trello\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto Example Gallery\n\n\n\nQuarto\n\nMarkdown\n\nDocumentation\n\n\n\nQuarto can produce a wide variety of output formats. This resource contains examples of the following categories: Articles & Reports, Presentations, Dashboards, Websites…\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n\n\nThe Design Philosophy of Great Tables\n\n\n\nDocumentation\n\nGreat Tables\n\nPython\n\n\n\nTables have come a long way and we’ve learned a lot from our continued research in tabular design. This article walks through the philosophy behind the Great Tables package\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nArticle\n\n\n\n\n\n\n\n\n\n\n\n\nZotero Quick-Start Guide\n\n\n\nCitation Management\n\n\n\nAn overview of Zotero’s features and capabilities from the Zotero team\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nDocumentation\n\n\n\n\n\n\n\n\n\n\n\n\nZotero Research Guide\n\n\n\nCitation Management\n\n\n\nA research guide developed by the University of Michigan Library with guidance on saving, organizing, and automating citation management\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nReference\n\n\n\n\n\n\n\n\n\n\n\n\nHow To Use Zotero (A Complete Beginner’s Guide)\n\n\n\nCitation Management\n\n\n\nA (12 min) tutorial on how to use Zotero for beginners\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\n\n\nUpcoming Sessions from the Teaching and Technology Collaborative\n\n\n\nCitation Management\n\n\n\nA listing of upcoming in-person workshops on citation management and research tools from the University of Michigan Library\n\n\n\n\n\nSkill Level\n\n\nIntermediate\n\n\n\n\n\nType\n\n\nWorkshops\n\n\n\n\n\n\n\n\n\n\n\n\n5 Best SQL Games to Master Database Skills in 2025\n\n\n\nSQL\n\nDatabases\n\n\n\nAn article that highlights engaging, game-based platforms that teach SQL through interactive challenges and storytelling, making learning both fun and effective\n\n\n\n\n\nSkill Level\n\n\nAll Levels\n\n\n\n\n\nType\n\n\nArticle\n\n\n\n\n\n\n\n\n\n\n\n\nBare Necessities of Data Management\n\n\n\nData Management\n\n\n\nA practical guide to the most essential data management practices research teams should implement before data collection begins, especially when resources are limited.\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nBlog\n\n\n\n\n\n\n\n\n\n\n\n\nData Management in Large-Scale Education Research\n\n\n\nData Management\n\nResearch Lifecycle\n\n\n\nA practical, open‑access handbook offering education researchers a step‑by‑step framework for implementing best-in-class data management throughout the full research…\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nBook\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling Functions\n\n\n\nData Wrangling\n\nTidyverse\n\nR\n\n\n\nA reference resource of data wrangling functions in R by Research Data Management Consultant, Crystal Lewis\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nWiki\n\n\n\n\n\n\n\n\n\n\n\n\nA Comparison of Packages to Generate Codebooks in R\n\n\n\nData Management\n\nDocumentation\n\nR\n\n\n\nSlides and a table from a presentation by Research Data Management Consultant, Crystal Lewis…\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nSlides\n\n\n\n\n\n\n\n\n\n\n\n\nREDCap Training Series\n\n\n\nDatabase Management\n\nREDCap\n\n\n\nA structured REDCap training series from ITHS offering ten classes, from basics to advanced topics like logic, longitudinal design, and mobile surveys, to support the full…\n\n\n\n\n\nSkill Level\n\n\nAll\n\n\n\n\n\nType\n\n\nTutorials\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to SQL\n\n\n\nSQL\n\nDatabase Management\n\n\n\nA concise, interactive four-week course teaching the fundamentals of connecting to and querying databases with SQL, covering basics like SELECT, JOIN, GROUP BY…\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nCourse\n\n\n\n\n\n\n\n\n\n\n\n\nR Workshop: Handling Uncertainty in your Data\n\n\n\nR\n\nData Wrangling\n\nData Visualization\n\n\n\nAn interactive R-based biostatistics course developed by Mario Reutter, focused on understanding and visualizing statistical precision and uncertainty using tools like…\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nWorkshop\n\n\n\n\n\n\n\n\n\n\n\n\nAI for the Skeptical Scholar: Practical Strategies for Using LLMs in Research\n\n\n\nGenerative AI\n\nLarge Language Models\n\n\n\nA concise, July 2025 workshop guide for experienced researchers on pragmatic, validated use of LLMs, covering prompt basics, literature-review support, coding assistance…\n\n\n\n\n\nSkill Level\n\n\nBeginner\n\n\n\n\n\nType\n\n\nWorkshop\n\n\n\n\n\n\n\n\nNo matching items\n\n  \n\n Back to top"
  }
]